# Trae Agent 配置文件示例
# 复制此文件为 trae_config.yaml 并填入你的配置

agents:
  trae_agent:
    enable_lakeview: true
    model: trae_agent_model  # Trae Agent 使用的模型配置名称
    max_steps: 200  # 最大代理步数
    tools:  # Trae Agent 使用的工具
      - bash
      - edit_file
      - sequential_thinking
      - task_done

model_providers:  # 模型提供商配置
  doubao:
    api_key: xxxxx
    provider: doubao
    base_url: https://ark.cn-beijing.volces.com/api/v3/
  ollama:
    api_key: "ssss"  # Ollama 通常不需要 API 密钥
    provider: ollama
    base_url: http://localhost:11434
  anthropic:
    api_key: your_anthropic_api_key
    provider: anthropic
  openai:
    api_key: your_openai_api_key
    provider: openai
  google:
    api_key: your_google_api_key
    provider: google
  openrouter:
    api_key: your_openrouter_api_key
    provider: openrouter

models:
  trae_agent_model:
    model_provider: doubao
    model: claude-3-5-sonnet-20241022
    max_tokens: 4096
    temperature: 0.5
    top_p: 1.0
    top_k: 1
    parallel_tool_calls: true
    max_retries: 3
    supports_tool_calling: true

  gpt4_model:
    model_provider: openai
    model: gpt-4o
    max_tokens: 4096
    temperature: 0.5
    top_p: 1.0
    top_k: 1
    parallel_tool_calls: true
    max_retries: 3
    supports_tool_calling: true

  gemini_model:
    model_provider: google
    model: gemini-2.0-flash-exp
    max_tokens: 4096
    temperature: 0.5
    top_p: 1.0
    top_k: 1
    parallel_tool_calls: true
    max_retries: 3
    supports_tool_calling: true
    candidate_count: 1

  claude_sonnet_model:
    model_provider: openrouter
    model: anthropic/claude-3-5-sonnet
    max_tokens: 4096
    temperature: 0.5
    top_p: 1.0
    top_k: 1
    parallel_tool_calls: true
    max_retries: 3
    supports_tool_calling: true

  doubao_model:
    model_provider: doubao
    model: doubao-seed-1.6
    max_tokens: 4096
    temperature: 0.5
    top_p: 1.0
    top_k: 1
    parallel_tool_calls: true
    max_retries: 3
    supports_tool_calling: true

  ollama_model:
    model_provider: ollama
    model: qwen2.5:7b
    max_tokens: 4096
    temperature: 0.5
    top_p: 1.0
    top_k: 1
    parallel_tool_calls: false  # Ollama 模型通常不支持工具调用
    max_retries: 3
    supports_tool_calling: false

lakeview:
  max_lines: 10  # Lakeview 显示的最大行数

# MCP 服务器配置（可选）
mcp_servers:
  playwright:
    command: npx
    args:
      - "@playwright/mcp@0.0.27"

# 允许的 MCP 服务器列表
allow_mcp_servers:
  - playwright
